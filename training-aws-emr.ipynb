{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on AWS-EMR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the actual training of the whole sparkify dataset on a 5 node cluster on AWS-EMR with a Pyspark kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` __Installing and Importing Packages__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.1` Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c549239ff3a14e279d19f1da53bb2217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2.4.7-amzn-1'"
     ]
    }
   ],
   "source": [
    "#checking spark version\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ed0ace3d684406879c7c2b2a51a9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>6</td><td>application_1619201621630_0007</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-30-159.us-east-2.compute.internal:20888/proxy/application_1619201621630_0007/\" class=\"emr-proxy-link\" emr-resource=\"j-1CGB3VFHJPGAO\n",
       "\" application-id=\"application_1619201621630_0007\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-20-220.us-east-2.compute.internal:8042/node/containerlogs/container_1619201621630_0007_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached https://files.pythonhosted.org/packages/51/51/48f3fc47c4e2144da2806dfb6629c4dd1fa3d5a143f9652b141e979a8ca9/pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib64/python3.7/site-packages (from pandas)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas)\n",
      "Collecting python-dateutil>=2.7.3 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas)\n",
      "Installing collected packages: python-dateutil, pandas\n",
      "Successfully installed pandas-1.2.4 python-dateutil-2.8.1\n",
      "\n",
      "Collecting matplotlib\n",
      "  Using cached https://files.pythonhosted.org/packages/ce/63/74c0b6184b6b169b121bb72458818ee60a7d7c436d7b1907bd5874188c55/matplotlib-3.4.1-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib64/python3.7/site-packages (from matplotlib)\n",
      "Collecting pyparsing>=2.2.1 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /mnt/tmp/1619217478920-0/lib/python3.7/site-packages (from matplotlib)\n",
      "Collecting pillow>=6.2.0 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/33/34/542152297dcc6c47a9dcb0685eac6d652d878ed3cea83bf2b23cb988e857/Pillow-8.2.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/46/231de802ade4225b76b96cffe419cf3ce52bbe92e3b092cf12db7d11c207/kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib)\n",
      "Installing collected packages: pyparsing, pillow, cycler, kiwisolver, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.1 pillow-8.2.0 pyparsing-2.4.7"
     ]
    }
   ],
   "source": [
    "# installing Packages\n",
    "sc.install_pypi_package(\"pandas\") \n",
    "sc.install_pypi_package(\"matplotlib\", \"https://pypi.org/simple\") #I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99bb76bd58f40338e611a3534dbe682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import re\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, DateType, IntegerType\n",
    "from pyspark.sql.functions import concat, lit, avg, split, isnan, when, count, col, sum, mean, stddev, min, max, round, udf, to_date, datediff \n",
    "from pyspark.sql import Window\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, Normalizer, StandardScaler, MinMaxScaler, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier, NaiveBayes, RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
    "from pyspark.mllib.util import MLUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` __Setting up a spark session__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuring the session\n",
    "\n",
    "%%configure -f \n",
    "\n",
    "{ \"conf\":{\n",
    "          \"spark.pyspark.python\": \"python3\", \"spark.pyspark.virtualenv.enabled\": \"true\", \"spark.pyspark.virtualenv.type\": \"native\", \"spark.pyspark.virtualenv.bin.path\": \"/usr/bin/virtualenv\", \"driverMemory\": \"6000M\"\n",
    "         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846eb12d92c54a3e97c1ce4193b253eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                    Version  \n",
      "-------------------------- ---------\n",
      "beautifulsoup4             4.9.3    \n",
      "boto                       2.49.0   \n",
      "click                      7.1.2    \n",
      "cycler                     0.10.0   \n",
      "jmespath                   0.10.0   \n",
      "joblib                     1.0.1    \n",
      "kiwisolver                 1.3.1    \n",
      "lxml                       4.6.2    \n",
      "matplotlib                 3.4.1    \n",
      "mysqlclient                1.4.2    \n",
      "nltk                       3.5      \n",
      "nose                       1.3.4    \n",
      "numpy                      1.16.5   \n",
      "pandas                     1.2.4    \n",
      "Pillow                     8.2.0    \n",
      "pip                        9.0.1    \n",
      "py-dateutil                2.2      \n",
      "pyparsing                  2.4.7    \n",
      "python-dateutil            2.8.1    \n",
      "python37-sagemaker-pyspark 1.4.1    \n",
      "pytz                       2021.1   \n",
      "PyYAML                     5.4.1    \n",
      "regex                      2021.3.17\n",
      "setuptools                 28.8.0   \n",
      "six                        1.13.0   \n",
      "tqdm                       4.59.0   \n",
      "wheel                      0.29.0   \n",
      "windmill                   1.6"
     ]
    }
   ],
   "source": [
    "sc.list_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c6bdca96bd4fd8b502eccddafb3f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26259199"
     ]
    }
   ],
   "source": [
    "# number of rows in the DataFrame\n",
    "df = spark.read.json('s3n://udacity-dsnd/sparkify/mini_sparkify_event_data.json')\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3` __Feature Engineering__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.1` Extracting useful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36515852c5934890ade1250fd2f48fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_data(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions removes all the rows where userId is empty or Null and \n",
    "    returns the dataframe.\n",
    "    \n",
    "    Input : DataFrame\n",
    "    Output : cleaned DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    df_new = df.filter(df[\"userId\"] != \"\")\n",
    "    df_new = df.filter(col('userId').isNull()==False)\n",
    "\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "def prepare_dataset(df): \n",
    "    \n",
    "    \"\"\"\n",
    "    This function will prepare the DataFrame for Machine Learning\n",
    "    by Extracting out the useful features, and engineering more \n",
    "    relevant features. The unique users will be kept in one of the DataFrames\n",
    "    which will be used for ML\n",
    "    \n",
    "    Input : DataFrame\n",
    "    Output : DataFrame to be used for applying Machine Learning and the modified input DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = clean_data(df)\n",
    "    \n",
    "    \n",
    "    \"\"\"Defining churn\"\"\"\n",
    "    cancellation_event = udf(lambda x: 1 if x == \"Cancellation Confirmation\" else 0, IntegerType())   \n",
    "    df = df.withColumn(\"churn\", cancellation_event(\"page\"))   \n",
    "    cancelled_users = df.select(['userId']).where(df.churn == 1).groupby('userId').count().toPandas()['userId'].values\n",
    "    \n",
    "    #Filling all the users who pressed the 'Cancellation Confirmation' button with 1\n",
    "    def fill_array(userId, features):\n",
    "        if(userId in cancelled_users): return 1\n",
    "        else : return 0\n",
    "        \n",
    "    fill_array_udf = udf(fill_array, IntegerType())\n",
    "    df = df.withColumn(\"churn\", fill_array_udf(col(\"userId\"), col(\"churn\")))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    w = Window.partitionBy('userId') #Partitioning the Data by User Id\n",
    "    df = df.withColumn('last_ts', max('ts').over(w)) #create last timestamp\n",
    "    df = df.withColumn('first_ts', min('ts').over(w)) #create first timestamp\n",
    "    \n",
    "    #This function will convert timestamp to date\n",
    "    def get_date_from_ts(ts):\n",
    "        return str(datetime.utcfromtimestamp(ts / 1000).strftime('%Y-%m-%d'))\n",
    "    \n",
    "    get_date_from_ts_udf = udf(get_date_from_ts, StringType())\n",
    "    df = df.withColumn('last_date', get_date_from_ts_udf(col('last_ts'))) #converting last timestamp to date\n",
    "    df = df.withColumn('first_date', get_date_from_ts_udf(col('first_ts'))) #converting first timestamp to date\n",
    "    \n",
    "    \n",
    "    df = df.withColumn('date', get_date_from_ts_udf(col('ts'))) #converting all timestamps to date\n",
    "    \n",
    "    df = df.withColumn('last_level',when(df.last_ts == df.ts, df.level)) #defining the last level (paid or free) of a user\n",
    "    \n",
    "    # create column avg_songs to calculate average number of songs per day\n",
    "    # first grouping on unique (userId, date) pair and then taking average \n",
    "    # over all the dates for a particular user\n",
    "    w = Window.partitionBy('userId', 'date')\n",
    "    songs = df.where(df.page == 'NextSong').select('userId', 'date', count('userId').over(w).alias('songs')).distinct()\n",
    "    w = Window.partitionBy('userId')\n",
    "    songs = songs.withColumn('avg_songs', avg('songs').over(w))\n",
    "    songs = songs.select(col(\"userId\").alias(\"songs_userId\"), 'avg_songs')\n",
    "    songs = songs.withColumn(\"avg_songs\", round(songs[\"avg_songs\"], 2))\n",
    "    \n",
    "    # create column avg_events to calculate average number of events per day\n",
    "    # first grouping on unique (userId, date) pair and then taking average \n",
    "    # over all the dates for a particular user\n",
    "    w = Window.partitionBy('userId', 'date')\n",
    "    events = df.select('userId', 'date', count('userId').over(w).alias('events')).distinct()\n",
    "    w = Window.partitionBy('userId')\n",
    "    events = events.withColumn('avg_events', avg('events').over(w))\n",
    "    events = events.select(col(\"userId\").alias(\"events_userId\"), 'avg_events')\n",
    "    events = events.withColumn(\"avg_events\", round(events[\"avg_events\"], 2))\n",
    "    \n",
    "    # calculate number of thumbs up for a user\n",
    "    w = Window.partitionBy('userId')\n",
    "    thumbsup = df.where(df.page == 'Thumbs Up').select('userId', count('userId').over(w).alias('thumbs_up')).distinct()\n",
    "    thumbsup = thumbsup.select(col(\"userId\").alias(\"thumbsup_userId\"), 'thumbs_up')\n",
    "    \n",
    "    # calculate number of thumbs down for a user\n",
    "    w = Window.partitionBy('userId')\n",
    "    thumbsdown = df.where(df.page == 'Thumbs Down').select('userId', count('userId').over(w).alias('thumbs_down')).distinct()\n",
    "    thumbsdown = thumbsdown.select(col(\"userId\").alias(\"thumbsdown_userId\"), 'thumbs_down')\n",
    "    \n",
    "    # calculate days since the date of the first event\n",
    "    df = df.withColumn(\"days_active\", \n",
    "              datediff(to_date(lit(datetime.now().strftime(\"%Y-%m-%d %H:%M\"))),\n",
    "                       to_date(\"first_date\",\"yyyy-MM-dd\")))\n",
    "    \n",
    "    # add column with state of the event based on location column\n",
    "    def get_state(location):\n",
    "        location = location.split(',')[-1].strip()\n",
    "        if (len(location) > 2):\n",
    "            location = location.split('-')[-1].strip()\n",
    "    \n",
    "        return location\n",
    "    \n",
    "    get_state_udf = udf(get_state, StringType())\n",
    "    df = df.withColumn('state', get_state_udf(col('location')))\n",
    "    \n",
    "    #add column with last location of the user\n",
    "    df = df.withColumn('last_state',when(df.last_ts == df.ts, df.state))\n",
    "    \n",
    "    # calculate number of add friends for a user\n",
    "    w = Window.partitionBy('userId')\n",
    "    addfriend = df.where(df.page == 'Add Friend').select('userId', count('userId').over(w).alias('addfriend')).distinct()\n",
    "    addfriend = addfriend.select(col(\"userId\").alias(\"addfriend_userId\"), 'addfriend')\n",
    "\n",
    "    # assemble everything into resulting dataset\n",
    "    df_ml = df.select('userId', 'gender', 'churn', 'last_level', 'days_active', 'last_state')\\\n",
    "    .dropna().drop_duplicates()\n",
    "    df_ml = df_ml.join(songs, df_ml.userId == songs.songs_userId).distinct()\n",
    "    df_ml = df_ml.join(events, df_ml.userId == events.events_userId).distinct()\n",
    "    df_ml = df_ml.join(thumbsup, df_ml.userId == thumbsup.thumbsup_userId, how='left').distinct()\n",
    "    df_ml = df_ml.fillna(0, subset=['thumbs_up'])\n",
    "    df_ml = df_ml.join(thumbsdown, df_ml.userId == thumbsdown.thumbsdown_userId, how='left').distinct()\n",
    "    df_ml = df_ml.fillna(0, subset=['thumbs_down'])\n",
    "    df_ml = df_ml.join(addfriend, df_ml.userId == addfriend.addfriend_userId, how='left').distinct()\n",
    "    df_ml = df_ml.fillna(0, subset=['addfriend'])\n",
    "    df_ml = df_ml.drop('songs_userId','events_userId', 'thumbsup_userId', 'thumbsdown_userId', 'addfriend_userId')\n",
    "    \n",
    "    return df, df_ml\n",
    "    \n",
    "df = spark.read.json('s3n://udacity-dsnd/sparkify/mini_sparkify_event_data.json')\n",
    "df.persist()\n",
    "\n",
    "df, df_ml = prepare_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b19286537f4457bb6bac764380d054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22263"
     ]
    }
   ],
   "source": [
    "#Total number of unique users in the Big Dataset\n",
    "\n",
    "df_ml.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0898b0369b4b30bf962a1e382210a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5002"
     ]
    }
   ],
   "source": [
    "# number of customers who churn \n",
    "df_ml.select('churn').where(col('churn')==1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the number of customers who churn are 5002 and ones who did not are (22263-5002)=17261\n",
    "`class imbalance of 3.45:1`. Therefore F1  score will be used as a metric of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729241c6c9b9481dbc4012520da7fb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artist', 'auth', 'firstName', 'gender', 'itemInSession', 'lastName', 'length', 'level', 'location', 'method', 'page', 'registration', 'sessionId', 'song', 'status', 'ts', 'userAgent', 'userId', 'churn', 'last_ts', 'first_ts', 'last_date', 'first_date', 'date', 'last_level', 'days_active', 'state', 'last_state']"
     ]
    }
   ],
   "source": [
    "#Total number of columns in the DataFrame\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c137ad9db3411492dec9674141cd48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25475717"
     ]
    }
   ],
   "source": [
    "#total number of rows in the DataFrame after cleaning\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65bf9ed44964615b85a9060068e4258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2048M'"
     ]
    }
   ],
   "source": [
    "#checking spark memory for this configuration\n",
    "sc._conf.get('spark.driver.memory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.2` Indexing of String columns and One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcc66bbf3564d8198f03eb04fad22d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# index and encode categorical features gender, level\n",
    "\n",
    "stringIndexerGender = StringIndexer(inputCol=\"gender\", outputCol=\"genderIndex\", handleInvalid = 'skip')\n",
    "stringIndexerLevel = StringIndexer(inputCol=\"last_level\", outputCol=\"levelIndex\", handleInvalid = 'skip')\n",
    "\n",
    "\n",
    "# OneHotEncoding these features, using OneHotEncoderEstimator because it has the transform method (updated from OneHotEncoder)\n",
    "encoder_gender = OneHotEncoderEstimator(inputCols=[\"genderIndex\"], outputCol=[\"genderVec\"])\n",
    "encoder_level = OneHotEncoderEstimator(inputCols=[\"levelIndex\"], outputCol=[\"levelVec\"])\n",
    "\n",
    "\n",
    "# create vector for features\n",
    "features = ['genderVec', 'levelVec', 'days_active', 'avg_songs', 'avg_events', 'thumbs_up', 'thumbs_down', 'addfriend']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "\n",
    "# initialize random forest classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10, maxDepth=5)\n",
    "\n",
    "# assemble pipeline\n",
    "pipeline = Pipeline(stages = [stringIndexerGender, stringIndexerLevel, encoder_gender,encoder_level, assembler, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4` __Applying Machine Learning__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.1` splitting the data and fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fdb85d20f2483288d4656cc00645f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ml = df_ml.withColumnRenamed(\"churn\", \"label\")\n",
    "\n",
    "train, test_valid = df_ml.randomSplit([0.6, 0.4], seed = 42)\n",
    "test, validation = test_valid.randomSplit([0.5, 0.5], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b4f88514924bf99d0188ad232cc1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.2` Observing Model Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5533088dacc4e16bd7d81ef9dbbc53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_train = model.transform(train)\n",
    "pred_test = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc59085455e44e34872eaddb28acdebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on train dataset is 0.793822913550703"
     ]
    }
   ],
   "source": [
    "predictionAndLabels = pred_train.rdd.map(lambda lp: (float(lp.prediction), float(lp.label)))\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# F1 score\n",
    "print(\"F1 score on train dataset is %s\" % metrics.fMeasure())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9f795dfbd74fdd8d66273d63e0af13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on test dataset is 0.7878650667874123"
     ]
    }
   ],
   "source": [
    "predictionAndLabels = pred_test.rdd.map(lambda lp: (float(lp.prediction), float(lp.label)))\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# F1 score\n",
    "print(\"F1 score on test dataset is %s\" % metrics.fMeasure())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see thant the F1 score on training Dataset is `0.79` and on Test Dataset is `0.78` for the `Random Forest Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef98f3240f4428c878c9af66696d325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_rf = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc37dd8766447fc84c0f929f0553ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#saving the random forest model\n",
    "model.save('s3://aws-emr-resources-816555935147-us-east-2/notebooks/model-rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.3` Setting up a pipeline for Gradient Boosted Trees model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54dfb75a37b64bbaa88315ec6fbd7e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# index and encode categorical features gender, level and state\n",
    "\n",
    "stringIndexerGender = StringIndexer(inputCol=\"gender\", outputCol=\"genderIndex\", handleInvalid = 'skip')\n",
    "stringIndexerLevel = StringIndexer(inputCol=\"last_level\", outputCol=\"levelIndex\", handleInvalid = 'skip')\n",
    "\n",
    "encoder_gender = OneHotEncoder(inputCol=\"genderIndex\", outputCol=\"genderVec\")\n",
    "encoder_level = OneHotEncoder(inputCol=\"levelIndex\", outputCol=\"levelVec\")\n",
    "\n",
    "features = ['genderVec', 'levelVec', 'days_active', 'avg_songs', 'avg_events', 'thumbs_up', 'thumbs_down', 'addfriend']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10, maxDepth=5)\n",
    "\n",
    "pipeline = Pipeline(stages = [stringIndexerGender, stringIndexerLevel, encoder_gender,encoder_level, assembler, gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ba6a5ceda64c2fa1f7a98f232f7bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fitting the gbt model\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.4` Testing Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4997c0a21c4f06a41f3353018665c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_train = model.transform(train)\n",
    "pred_test = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6734b53aeba5491f90800c0928afac7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.7/site-packages/awseditorssparkmonitoringwidget-1.0-py3.7.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n",
      "    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\n",
      "KeyError: 610\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on train dataset is 0.8093030212384086"
     ]
    }
   ],
   "source": [
    "predictionAndLabels = pred_train.rdd.map(lambda lp: (float(lp.prediction), float(lp.label)))\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# F1 score\n",
    "print(\"F1 score on train dataset is %s\" % metrics.fMeasure())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59ab75657de482aa9fd11b4b7312f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on test dataset is 0.8066561014263075"
     ]
    }
   ],
   "source": [
    "predictionAndLabels = pred_test.rdd.map(lambda lp: (float(lp.prediction), float(lp.label)))\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# F1 score\n",
    "print(\"F1 score on test dataset is %s\" % metrics.fMeasure())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see thant the F1 score on training Dataset is `0.809` and on Test Dataset is `0.806` for the `Random Forest Model`. It is performing slightly better that Random Forest model so I am using it for deployment purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90f0a1a9db54eb488fcdcfb37978c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save('s3://aws-emr-resources-816555935147-us-east-2/notebooks/model-gbt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we went through the process of Engineering the features of the __large dataset containing 26 million rows and then extracting the unique users.The resulting DataSet that we get is about 22 thousand rows which is suitable for applying Machine Learning__\n",
    "\n",
    "I have applied two models -Random Forest and Gradient Boosted trees and find that the performance of GBT is slightly better. I have saved both the trained models into the S3 bucket and then synced the bucket with a local folder.\n",
    "__I will be using the GBT model for the case of application based on Flask. Thereafter I will be deploying the model on a web-server like AWS.__\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
